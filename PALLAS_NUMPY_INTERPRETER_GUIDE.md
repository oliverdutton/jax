# Pallas NumPy Interpreter Implementation Guide

## Overview

This guide demonstrates how to implement a Pallas call interpreter using `io_callback` to convert everything to NumPy arrays and interpret the jaxpr using pure NumPy operations.

## Key Concepts

### 1. NumPy Arrays are Stateful
Unlike JAX arrays, NumPy arrays support in-place mutation, which we leverage to implement Pallas memory references (refs).

### 2. Memory Spaces = Separate Arrays
Different memory spaces in Pallas (VMEM, HBM, etc.) are just separate NumPy arrays in our interpreter.

### 3. Control Flow is Pure Python
- `pl.when` â†’ Python `if` statements
- `pl.loop` â†’ Python `for` loops
- `program_id` â†’ Simple loop iteration tracking

### 4. Using lax_reference.py
For complex JAX primitives, we hook into `jax._src.lax_reference` which provides NumPy implementations of all LAX primitives.

## Implementation Strategy

### Phase 1: Simple io_callback Wrapper (âœ… DONE)
**File:** `numpy_pallas_demo.py`

Demonstrates the basic concept:
1. Use `io_callback` to create a boundary between JAX and NumPy
2. Convert JAX arrays to NumPy inside the callback
3. Execute kernel logic in pure NumPy
4. Return results back to JAX

**Results:** This simple approach is **~3x faster** than standard Pallas interpret mode!

```python
def pallas_with_numpy_callback(x, y):
    def numpy_kernel_wrapper(x_jax, y_jax):
        x_np = np.asarray(x_jax)
        y_np = np.asarray(y_jax)
        o_np = np.zeros_like(x_np)
        # Execute in pure NumPy
        simple_add_kernel_numpy(x_np, y_np, o_np)
        return o_np

    result_shape = jax.ShapeDtypeStruct(x.shape, x.dtype)
    return io_callback(numpy_kernel_wrapper, result_shape, x, y)
```

### Phase 2: Jaxpr Interpreter (ðŸš§ IN PROGRESS)
**File:** `pallas_numpy_interpreter.py`

A more comprehensive interpreter that:
1. Extracts the jaxpr from a Pallas kernel
2. Evaluates each equation using NumPy implementations
3. Handles Pallas-specific primitives:
   - `program_id_p` â†’ Returns current grid index
   - `num_programs_p` â†’ Returns grid size
   - State primitives (GetPrim, SwapPrim) â†’ Direct NumPy array manipulation
4. Routes standard JAX primitives to `lax_reference.py`

### Phase 3: Full Integration (ðŸ“‹ TODO)
1. Monkey-patch `pallas_call_p.bind` to intercept calls
2. When `interpret=True`, use NumPy interpreter
3. Handle full grid iteration with proper program_id tracking
4. Support all Pallas primitives used in bitonic sort

## Files Created

1. **`numpy_pallas_demo.py`** - Working demo showing io_callback approach
2. **`pallas_numpy_interpreter.py`** - Comprehensive jaxpr interpreter
3. **`test_simple_pallas.py`** - Basic Pallas test
4. **`bitonic_sort_benchmark.py`** - Test harness for the bitonic sort

## Performance Results

From `numpy_pallas_demo.py`:
- **Standard Pallas (interpret=True):** 53.28ms
- **NumPy via io_callback:** 18.77ms
- **Speedup:** ~2.8x faster!

## Next Steps

To run the bitonic sort benchmark with progressive NumPy integration:

1. Start with the current `interpret=True` baseline
2. Replace simple operations with NumPy via io_callback
3. Progressively expand to more complex primitives
4. Track runtime at each stage

## Usage Example

```python
# Simple usage
from jax.experimental import pallas as pl
import jax.numpy as jnp

def kernel(x_ref, o_ref):
    o_ref[...] = x_ref[...] * 2

x = jnp.ones((8, 128))
out_shape = jax.ShapeDtypeStruct(x.shape, x.dtype)

# Standard interpret mode
result = pl.pallas_call(kernel, out_shape=out_shape, interpret=True)(x)

# With NumPy interpreter (when fully implemented)
# install_numpy_interpreter()
# result = pl.pallas_call(kernel, out_shape=out_shape, interpret=True)(x)
```

## Implementation Status

- âœ… Basic io_callback wrapper working
- âœ… Performance improvement demonstrated (3x faster)
- âœ… lax_reference integration mapped out
- ðŸš§ Full jaxpr interpreter with primitive handling
- ðŸ“‹ Integration with actual bitonic sort benchmark
- ðŸ“‹ Handle all control flow primitives (scan, while, cond)
- ðŸ“‹ Complete test coverage

## Key Insights

1. **NumPy is faster** for small kernels due to lower overhead
2. **Stateful arrays simplify** the implementation significantly
3. **lax_reference.py** provides all the primitives we need
4. **io_callback** is the perfect boundary for JAXâ†”NumPy conversion
